{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Shishir_file_hw5_Q1.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyN2IpvwIjZBNqeaJiUARUKJ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"4a0eaa78db2a45cc8d4c5b66789c4b0a":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_view_name":"VBoxView","_dom_classes":[],"_model_name":"VBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_5befefdd7bc342f9ab18f2efb671b5b6","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_0418001a927d4f7ba6c51105f483d2fd","IPY_MODEL_450e20d81af94d1598f9c6a4cbd5f777"]}},"5befefdd7bc342f9ab18f2efb671b5b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0418001a927d4f7ba6c51105f483d2fd":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_view_name":"LabelView","style":"IPY_MODEL_f79f30d333ab45c6b5785eb61e87a2de","_dom_classes":[],"description":"","_model_name":"LabelModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 0.07MB of 0.07MB uploaded (0.00MB deduped)\r","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_dba768a73a1c45e5b796b34e7a69da73"}},"450e20d81af94d1598f9c6a4cbd5f777":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_fe42536b0d534b59bf0268fafe45d301","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b9f6c8197e444d3e9b655dfc3c9c0eaf"}},"f79f30d333ab45c6b5785eb61e87a2de":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"dba768a73a1c45e5b796b34e7a69da73":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fe42536b0d534b59bf0268fafe45d301":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"b9f6c8197e444d3e9b655dfc3c9c0eaf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"sCVFh3-r73Fv"},"source":["## **Question 1:** \n","Implement CNN on CIFAR-10 dataset (5 Points)\n","\n","\n","•\tUse the following network architecture\n","•\tConvolutional layer (with bias) with 32 5x5 filters, with zero-padding of 2\n","•\tReLU\n","•\tConvolutional layer (with bias) with 16 3x3 filters, with zero-padding of 1\n","•\tReLU\n","•\tFully-connected layer (with bias) to compute scores for 10 classes\n","\n","Note that we have no softmax activation here after our fully connected layer: this is because PyTorch's cross-entropy loss performs a softmax activation.\n","\n","\n","•\tYou should optimize your model using stochastic gradient descent with a Nesterov momentum of 0.9.\n","•\tUse learning rate of 1e-2\n","•\tYou should initialize the weight matrices of the model using the Kaiming normal initialization method.\n"]},{"cell_type":"code","metadata":{"id":"DC5mNLEmGnon","executionInfo":{"status":"ok","timestamp":1636949186475,"user_tz":360,"elapsed":2636,"user":{"displayName":"Shishir sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgQXaVDw08iapj6wCi7UM1wKF5TLN-xVAZbzWZzDA=s64","userId":"18124275142639548991"}}},"source":["%%capture\n","!pip install wandb --upgrade"],"execution_count":47,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Nn9N9xOZGs1g","executionInfo":{"status":"ok","timestamp":1636949186483,"user_tz":360,"elapsed":62,"user":{"displayName":"Shishir sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgQXaVDw08iapj6wCi7UM1wKF5TLN-xVAZbzWZzDA=s64","userId":"18124275142639548991"}},"outputId":"185def1f-fa16-4202-977d-23a18df9426a"},"source":["# Import wandb\n","import wandb\n","\n","# Login to W&B\n","wandb.login()"],"execution_count":48,"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":48}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4xJinn5Cvugc","executionInfo":{"status":"ok","timestamp":1636949188830,"user_tz":360,"elapsed":2375,"user":{"displayName":"Shishir sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgQXaVDw08iapj6wCi7UM1wKF5TLN-xVAZbzWZzDA=s64","userId":"18124275142639548991"}},"outputId":"0ac84f1f-c144-4a80-ee1c-687618439657"},"source":["pip install torch-lr-finder"],"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch-lr-finder in /usr/local/lib/python3.7/dist-packages (0.2.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from torch-lr-finder) (3.2.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-lr-finder) (4.62.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torch-lr-finder) (21.2)\n","Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from torch-lr-finder) (1.10.0+cu111)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-lr-finder) (1.19.5)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->torch-lr-finder) (3.10.0.2)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->torch-lr-finder) (2.8.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->torch-lr-finder) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->torch-lr-finder) (0.11.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->torch-lr-finder) (2.4.7)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->torch-lr-finder) (1.15.0)\n"]}]},{"cell_type":"code","metadata":{"id":"TqYqOtp5yluv","executionInfo":{"status":"ok","timestamp":1636949188841,"user_tz":360,"elapsed":35,"user":{"displayName":"Shishir sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgQXaVDw08iapj6wCi7UM1wKF5TLN-xVAZbzWZzDA=s64","userId":"18124275142639548991"}}},"source":["# Importing the necessary libraries\n","import torch\n","import torch.nn as nn\n","import torchvision\n","import torchvision.transforms as transforms\n","import torch.nn.functional as F\n","from torchsummary import summary\n","\n","from torch.optim.lr_scheduler import ReduceLROnPlateau, ExponentialLR, CyclicLR, OneCycleLR, StepLR\n","from torch_lr_finder import LRFinder\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.metrics import confusion_matrix\n","import random\n","\n","from datetime import datetime\n","from pathlib import Path\n","import plotly.io as pio\n","pio.renderers.default = 'colab'"],"execution_count":50,"outputs":[]},{"cell_type":"code","metadata":{"id":"CQQbjmDl5Got","executionInfo":{"status":"ok","timestamp":1636949189004,"user_tz":360,"elapsed":193,"user":{"displayName":"Shishir sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgQXaVDw08iapj6wCi7UM1wKF5TLN-xVAZbzWZzDA=s64","userId":"18124275142639548991"}}},"source":["# Import random function\n","import random\n","\n","# Fix seed value\n","SEED = 2345\n","random.seed(SEED)\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","torch.cuda.manual_seed(SEED)\n","torch.backends.cudnn.deterministic = True"],"execution_count":51,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XJPqqFJulaGW","executionInfo":{"status":"ok","timestamp":1636949189006,"user_tz":360,"elapsed":37,"user":{"displayName":"Shishir sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgQXaVDw08iapj6wCi7UM1wKF5TLN-xVAZbzWZzDA=s64","userId":"18124275142639548991"}},"outputId":"5127f3e9-67a1-4b53-9b4a-39f5e7706611"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":52,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","metadata":{"id":"omgjHGvS2VBQ","executionInfo":{"status":"ok","timestamp":1636949189008,"user_tz":360,"elapsed":21,"user":{"displayName":"Shishir sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgQXaVDw08iapj6wCi7UM1wKF5TLN-xVAZbzWZzDA=s64","userId":"18124275142639548991"}}},"source":["data_folder = Path('/content/drive/MyDrive/Data/DL')"],"execution_count":53,"outputs":[]},{"cell_type":"code","metadata":{"id":"27OJT5oq2WXI","executionInfo":{"status":"ok","timestamp":1636949189013,"user_tz":360,"elapsed":23,"user":{"displayName":"Shishir sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgQXaVDw08iapj6wCi7UM1wKF5TLN-xVAZbzWZzDA=s64","userId":"18124275142639548991"}}},"source":["lecture_folder = Path('/content/drive/MyDrive/Deep Learning/HW5')"],"execution_count":54,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vcj3wFSn2WeS"},"source":["The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images."]},{"cell_type":"markdown","metadata":{"id":"FAof5BqiyD1L"},"source":["## **Data Download and Transform to tensor**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LvvRv9msIoWb","executionInfo":{"status":"ok","timestamp":1636949191593,"user_tz":360,"elapsed":2602,"user":{"displayName":"Shishir sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgQXaVDw08iapj6wCi7UM1wKF5TLN-xVAZbzWZzDA=s64","userId":"18124275142639548991"}},"outputId":"2393af9d-ecaf-435a-b8f8-ea44f45fb3c7"},"source":["# Transform to convert images to pytorch tensors and normalize the data\n","trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.4914,0.4822,0.4655), (0.3530,0.1994,0.2010))])\n","train_full = torchvision.datasets.CIFAR10(root=data_folder,\n","                                              train=True, \n","                                              transform=trans,\n","                                              download=True)\n","trainset, validset = torch.utils.data.random_split(train_full, [40000, 10000], generator=torch.Generator().manual_seed(42) )\n","testset  = torchvision.datasets.CIFAR10(root=data_folder,\n","                                              train=False, \n","                                              transform=trans,\n","                                              download=True)"],"execution_count":55,"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZJ3i3ItstVCC","executionInfo":{"status":"ok","timestamp":1636949191599,"user_tz":360,"elapsed":54,"user":{"displayName":"Shishir sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgQXaVDw08iapj6wCi7UM1wKF5TLN-xVAZbzWZzDA=s64","userId":"18124275142639548991"}},"outputId":"4f4e8592-a356-4fd1-d59a-5fbafa0696e0"},"source":["classes = train_full.classes\n","classes"],"execution_count":56,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['airplane',\n"," 'automobile',\n"," 'bird',\n"," 'cat',\n"," 'deer',\n"," 'dog',\n"," 'frog',\n"," 'horse',\n"," 'ship',\n"," 'truck']"]},"metadata":{},"execution_count":56}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yi8d9uFtxgbZ","executionInfo":{"status":"ok","timestamp":1636949199449,"user_tz":360,"elapsed":7873,"user":{"displayName":"Shishir sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgQXaVDw08iapj6wCi7UM1wKF5TLN-xVAZbzWZzDA=s64","userId":"18124275142639548991"}},"outputId":"e4011c08-a0dd-4d25-d20d-a10990374fe5"},"source":["class_count = {}\n","for _, index in train_full:\n","    label = classes[index]\n","    if label not in class_count:\n","        class_count[label] = 0\n","    class_count[label] += 1\n","class_count"],"execution_count":57,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'airplane': 5000,\n"," 'automobile': 5000,\n"," 'bird': 5000,\n"," 'cat': 5000,\n"," 'deer': 5000,\n"," 'dog': 5000,\n"," 'frog': 5000,\n"," 'horse': 5000,\n"," 'ship': 5000,\n"," 'truck': 5000}"]},"metadata":{},"execution_count":57}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"23I5nK2C3zPj","executionInfo":{"status":"ok","timestamp":1636949199451,"user_tz":360,"elapsed":180,"user":{"displayName":"Shishir sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgQXaVDw08iapj6wCi7UM1wKF5TLN-xVAZbzWZzDA=s64","userId":"18124275142639548991"}},"outputId":"c9151784-084e-4312-a336-47077e316617"},"source":["train_full.data.shape"],"execution_count":58,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(50000, 32, 32, 3)"]},"metadata":{},"execution_count":58}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4H5TgmFk4mS4","executionInfo":{"status":"ok","timestamp":1636949199460,"user_tz":360,"elapsed":165,"user":{"displayName":"Shishir sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgQXaVDw08iapj6wCi7UM1wKF5TLN-xVAZbzWZzDA=s64","userId":"18124275142639548991"}},"outputId":"a992a33b-519b-4db8-d996-a1f003cac499"},"source":["testset.data.shape"],"execution_count":59,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(10000, 32, 32, 3)"]},"metadata":{},"execution_count":59}]},{"cell_type":"code","metadata":{"id":"2J4yruMLxI8T","executionInfo":{"status":"ok","timestamp":1636949199464,"user_tz":360,"elapsed":137,"user":{"displayName":"Shishir sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgQXaVDw08iapj6wCi7UM1wKF5TLN-xVAZbzWZzDA=s64","userId":"18124275142639548991"}}},"source":[""],"execution_count":59,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U5PslDp5R7Ff"},"source":["### Check Transformation\n","\n","- Check if transformation are working correctly.\n","- The transformations are applied at the time of calling dataloader"]},{"cell_type":"code","metadata":{"id":"xj4RiSmGM984","executionInfo":{"status":"ok","timestamp":1636949199467,"user_tz":360,"elapsed":134,"user":{"displayName":"Shishir sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgQXaVDw08iapj6wCi7UM1wKF5TLN-xVAZbzWZzDA=s64","userId":"18124275142639548991"}}},"source":["check_loader = torch.utils.data.DataLoader(trainset, batch_size = 32, shuffle = True)"],"execution_count":60,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SrO2i0utr2fS","executionInfo":{"status":"ok","timestamp":1636949199471,"user_tz":360,"elapsed":130,"user":{"displayName":"Shishir sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgQXaVDw08iapj6wCi7UM1wKF5TLN-xVAZbzWZzDA=s64","userId":"18124275142639548991"}},"outputId":"d7e7e0d0-7b89-4f08-b929-d0dc3ef12a04"},"source":["# check number of batches\n","len(check_loader)"],"execution_count":61,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1250"]},"metadata":{},"execution_count":61}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KSYReXcBsEjs","executionInfo":{"status":"ok","timestamp":1636949199475,"user_tz":360,"elapsed":116,"user":{"displayName":"Shishir sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgQXaVDw08iapj6wCi7UM1wKF5TLN-xVAZbzWZzDA=s64","userId":"18124275142639548991"}},"outputId":"dc797807-4bae-4bb4-e1f6-b18ac41414c8"},"source":["# check total training examples\n","len(check_loader.dataset)"],"execution_count":62,"outputs":[{"output_type":"execute_result","data":{"text/plain":["40000"]},"metadata":{},"execution_count":62}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JGIeEEzEjRlP","executionInfo":{"status":"ok","timestamp":1636949199478,"user_tz":360,"elapsed":105,"user":{"displayName":"Shishir sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgQXaVDw08iapj6wCi7UM1wKF5TLN-xVAZbzWZzDA=s64","userId":"18124275142639548991"}},"outputId":"1f735a21-b085-43d1-bef3-2e5670e159ca"},"source":["# check imputs and outputs \n","for input, target in check_loader:\n","  print(f'shape of inputs is :{input.shape}')\n","  print(f'\\nmax input value  :{input.max()}')\n","  print(f'\\nmin input value  :{input.min()}')\n","  print(f'\\nmean input value  :{input.mean()}')\n","  print(f'\\nstd input value  :{input.std()}')\n","  print(f'\\nshape of targets is :{target.shape}')\n","   \n","  break"],"execution_count":63,"outputs":[{"output_type":"stream","name":"stdout","text":["shape of inputs is :torch.Size([32, 3, 32, 32])\n","\n","max input value  :2.6592040061950684\n","\n","min input value  :-2.418254852294922\n","\n","mean input value  :-0.08662816882133484\n","\n","std input value  :1.1399555206298828\n","\n","shape of targets is :torch.Size([32])\n"]}]},{"cell_type":"markdown","metadata":{"id":"QVUnc93NFv6V"},"source":["First let's define labels for our dataset as dataset contains numerical values for now."]},{"cell_type":"markdown","metadata":{"id":"mS6k4qqgb3WC"},"source":["## Get Labels"]},{"cell_type":"code","metadata":{"id":"Qsuren0LCxEo","executionInfo":{"status":"ok","timestamp":1636949199481,"user_tz":360,"elapsed":98,"user":{"displayName":"Shishir sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgQXaVDw08iapj6wCi7UM1wKF5TLN-xVAZbzWZzDA=s64","userId":"18124275142639548991"}}},"source":["def get_CIFAR10_labels(labels):  \n","    \"\"\" \n","    Function to generate labels.\n","    Input: numerical labels\n","    Output: actual string labels\n","    \"\"\"\n","\n","    # Create a list of labels\n","    text_labels = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n","                   'dog', 'frog', 'horse', 'ship', 'truck']\n","\n","    # Return text_labels according to numerical values\n","    return [text_labels[int(i)] for i in labels]"],"execution_count":64,"outputs":[]},{"cell_type":"code","metadata":{"id":"eabvPwR76YHh","executionInfo":{"status":"ok","timestamp":1636949199483,"user_tz":360,"elapsed":97,"user":{"displayName":"Shishir sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgQXaVDw08iapj6wCi7UM1wKF5TLN-xVAZbzWZzDA=s64","userId":"18124275142639548991"}}},"source":[""],"execution_count":64,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5tL7j8siW9qm"},"source":["# Model CNN"]},{"cell_type":"code","metadata":{"id":"FvwkXedfDkDa","executionInfo":{"status":"ok","timestamp":1636949199486,"user_tz":360,"elapsed":97,"user":{"displayName":"Shishir sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgQXaVDw08iapj6wCi7UM1wKF5TLN-xVAZbzWZzDA=s64","userId":"18124275142639548991"}}},"source":["class CIFAR10CNN(nn.Module):\n","    \n","    def __init__(self):\n","\n","      super().__init__()\n","\n","      super(CIFAR10CNN, self).__init__()\n","      \n","\n","      \n","      self.conv1_layer = nn.Sequential(\n","          nn.Conv2d(in_channels=3, out_channels=32, kernel_size=5, padding='same'), # 32 * 32\n","          nn.ReLU(),\n","          nn.BatchNorm2d(32),\n","          nn.Conv2d(in_channels=32, out_channels=32, kernel_size=5, padding='same'), # 32 * 32\n","          nn.ReLU(),\n","          nn.MaxPool2d(kernel_size=2, stride = 2 ) # 16 * 16\n","      )\n","\n","      self.conv2_layer = nn.Sequential(\n","          nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding='same'), # 16 * 16\n","          nn.ReLU(),\n","          nn.BatchNorm2d(64),\n","          nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding='same'), # 16 * 16\n","          nn.ReLU(),\n","          nn.MaxPool2d(kernel_size=2) # 8 * 8\n","      )\n","\n","      \n","\n","      self.flatten = nn.Flatten()\n","      \n","      self.fc1 = nn.Linear(8*8*64, out_features=128)\n","      \n","      self.fc2 = nn.Linear(128, 10)\n","\n","      #self.fc3 = nn.Linear(512, 10)\n","\n","      self.drop1 = nn.Dropout(0.2)\n","      self.drop2 = nn.Dropout(0.2)\n","      \n","      \n","      \n","        \n","    def forward(self, x):\n","        # conv layers\n","        out = self.conv1_layer(x)\n","        out = self.conv2_layer(out)\n","        #out = self.conv3_layer(out)\n","\n","        # flatten befrore input to linear layer\n","        out = self.flatten(out)\n","\n","        # linear hidden layers\n","        out = F.relu(self.fc1(out))\n","        out = self.drop1(out)\n","        #out = F.relu(self.fc2(out))\n","        #out = self.drop2(out)\n","\n","        # output layer - no softmax as it is applied by nn.CrossEntropyLoss\n","\n","        out = self.fc2(out)\n","        \n","        return out"],"execution_count":65,"outputs":[]},{"cell_type":"code","metadata":{"id":"jg9UH-rI8BCV","executionInfo":{"status":"ok","timestamp":1636949199492,"user_tz":360,"elapsed":99,"user":{"displayName":"Shishir sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgQXaVDw08iapj6wCi7UM1wKF5TLN-xVAZbzWZzDA=s64","userId":"18124275142639548991"}}},"source":[""],"execution_count":65,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FNMklOPdTunl","executionInfo":{"status":"ok","timestamp":1636949199755,"user_tz":360,"elapsed":356,"user":{"displayName":"Shishir sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgQXaVDw08iapj6wCi7UM1wKF5TLN-xVAZbzWZzDA=s64","userId":"18124275142639548991"}},"outputId":"4189d308-15c8-4197-c9b2-f3464e709b22"},"source":["summary(CIFAR10CNN().cuda(), (3,32,32))"],"execution_count":66,"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1           [-1, 32, 32, 32]           2,432\n","              ReLU-2           [-1, 32, 32, 32]               0\n","       BatchNorm2d-3           [-1, 32, 32, 32]              64\n","            Conv2d-4           [-1, 32, 32, 32]          25,632\n","              ReLU-5           [-1, 32, 32, 32]               0\n","         MaxPool2d-6           [-1, 32, 16, 16]               0\n","            Conv2d-7           [-1, 64, 16, 16]          18,496\n","              ReLU-8           [-1, 64, 16, 16]               0\n","       BatchNorm2d-9           [-1, 64, 16, 16]             128\n","           Conv2d-10           [-1, 64, 16, 16]          36,928\n","             ReLU-11           [-1, 64, 16, 16]               0\n","        MaxPool2d-12             [-1, 64, 8, 8]               0\n","          Flatten-13                 [-1, 4096]               0\n","           Linear-14                  [-1, 128]         524,416\n","          Dropout-15                  [-1, 128]               0\n","           Linear-16                   [-1, 10]           1,290\n","================================================================\n","Total params: 609,386\n","Trainable params: 609,386\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.01\n","Forward/backward pass size (MB): 2.00\n","Params size (MB): 2.32\n","Estimated Total Size (MB): 4.34\n","----------------------------------------------------------------\n"]}]},{"cell_type":"markdown","metadata":{"id":"Ry-7lHYVPlPP"},"source":["# Training Functions"]},{"cell_type":"markdown","metadata":{"id":"z3GdVoTjh7YD"},"source":["## Training Epoch "]},{"cell_type":"code","metadata":{"id":"Pv4x22lZMn5p","executionInfo":{"status":"ok","timestamp":1636949199757,"user_tz":360,"elapsed":31,"user":{"displayName":"Shishir sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgQXaVDw08iapj6wCi7UM1wKF5TLN-xVAZbzWZzDA=s64","userId":"18124275142639548991"}}},"source":["def train(train_loader, model, optimizer, loss_function, log_batch, log_interval, grad_clipping, max_norm):\n","\n","  \"\"\" \n","  Function for training the model in each epoch\n","  Input: iterator for train dataset, initial weights and bias, epochs, learning rate.\n","  Output: final weights, bias, train loss, train accuracy\n","  \"\"\"\n","  # initilalize variables as global\n","  # these counts will be updated every epoch\n","  global example_ct_train\n","  global batch_ct_train\n","\n","  # Training Loop loop\n","  # Initialize train_loss at the he start of the epoch\n","  running_train_loss = 0\n","  running_train_correct = 0\n","  \n","  # put the model in training mode\n","  model.train()\n","\n","  # Iterate on batches from the dataset using train_loader\n","  for input, targets in train_loader:\n","    \n","    # move inputs and outputs to GPUs\n","    input = input.to(device)\n","    targets = targets.to(device)\n","\n","    # Forward pass\n","    output = model(input)\n","    loss = loss_function(output, targets)\n","\n","    # Correct prediction\n","    y_pred = torch.argmax(output, dim = 1)\n","    correct = torch.sum(y_pred == targets)\n","\n","    example_ct_train +=  len(targets)\n","    batch_ct_train += 1\n","\n","    # set gradients to zero \n","    optimizer.zero_grad()\n","\n","    # Backward pass\n","    loss.backward()\n","\n","    # Gradient Clipping\n","    if grad_clipping:\n","      nn.utils.clip_grad_norm_(model.parameters(), max_norm=max_norm, norm_type=2)\n","\n","    # Update parameters using their gradient\n","    optimizer.step()\n","          \n","    # Add train loss of a batch \n","    running_train_loss += loss.item()\n","\n","    # Add Corect counts of a batch\n","    running_train_correct += correct\n","\n","    # log batch loss and accuracy\n","    if log_batch:\n","      if ((batch_ct_train + 1) % log_interval) == 0:\n","        wandb.log({f\"Train Batch Loss  :\": loss})\n","        wandb.log({f\"Train Batch Acc :\": correct/len(targets)})\n","\n","    #scheduler.step()\n","  # Calculate mean train loss for the whole dataset for a particular epoch\n","  train_loss = running_train_loss/len(train_loader)\n","\n","\n","\n","  # Calculate accuracy for the whole dataset for a particular epoch\n","  train_acc = running_train_correct/len(train_loader.dataset)\n","\n","  return train_loss, train_acc"],"execution_count":67,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Aic8wk5niFCz"},"source":["## Validation/Test Epoch"]},{"cell_type":"code","metadata":{"id":"pHP1WKDessiI","executionInfo":{"status":"ok","timestamp":1636949199761,"user_tz":360,"elapsed":33,"user":{"displayName":"Shishir sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgQXaVDw08iapj6wCi7UM1wKF5TLN-xVAZbzWZzDA=s64","userId":"18124275142639548991"}}},"source":["def valid(loader, model, optimizer, loss_function, log_batch, log_interval):\n","\n","  \"\"\" \n","  Function for training the model and plotting the graph for train & valid loss vs epoch.\n","  Input: iterator for train dataset, initial weights and bias, epochs, learning rate, batch size.\n","  Output: final weights, bias and train loss and valid loss for each epoch.\n","  \"\"\"\n","\n","  # initilalize variables as global\n","  # these counts will be updated every epoch\n","  global example_ct_valid\n","  global batch_ct_valid\n","\n","  # Validation loop\n","  # Initialize train_loss at the he strat of the epoch\n","  running_valid_loss = 0\n","  running_valid_correct = 0\n","  \n","  # put the model in evaluation mode\n","  model.eval()\n","\n","  with torch.no_grad():\n","    for input,targets in loader:\n","\n","      # move inputs and outputs to GPUs\n","      input = input.to(device)\n","      targets = targets.to(device)\n","\n","      # Forward pass\n","      output = model(input)\n","      loss = loss_function(output,targets)\n","\n","      # Correct Predictions\n","      y_pred = torch.argmax(output, dim = 1)\n","      correct = torch.sum(y_pred == targets)\n","\n","      # count of images and batches\n","      example_ct_valid +=  len(targets)\n","      batch_ct_valid += 1\n","\n","      # Add valid loss of a batch \n","      running_valid_loss += loss.item()\n","\n","      # Add correct count for each batch\n","      running_valid_correct += correct\n","\n","      # log batch loss and accuracy\n","      if log_batch:\n","        if ((batch_ct_valid + 1) % log_interval) == 0:\n","          wandb.log({f\"Valid Batch Loss  :\": loss})\n","          wandb.log({f\"Valid Batch Accuracy :\": correct/len(targets)})\n","\n","\n","    # Calculate mean valid loss for the whole dataset for a particular epoch\n","    valid_loss = running_valid_loss/len(valid_loader)\n","\n","    # scheduler step\n","    scheduler.step(valid_loss)\n","    # scheduler.step()\n","\n","    # Calculate accuracy for the whole dataset for a particular epoch\n","    valid_acc = running_valid_correct/len(valid_loader.dataset)\n","    \n","  return valid_loss, valid_acc"],"execution_count":68,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UwF70eqE6n_v"},"source":["##  Model Training Loop\n"]},{"cell_type":"code","metadata":{"id":"KeCKVgg-5FiZ","executionInfo":{"status":"ok","timestamp":1636949199764,"user_tz":360,"elapsed":34,"user":{"displayName":"Shishir sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgQXaVDw08iapj6wCi7UM1wKF5TLN-xVAZbzWZzDA=s64","userId":"18124275142639548991"}}},"source":["def train_loop(train_loader, valid_loader, model, loss_function, optimizer, epochs, device, patience, early_stopping,\n","               file_model):\n","\n","  '''\n","  model: specify your model for training\n","  criterion: loss function \n","  optimizer: optimizer like SGD , ADAM etc.\n","  train loader: function to carete batches for training data\n","  loader : function to create batches for valid data set\n","  file_model : specify file name for saving your model. This way we can upload the model weights from file. We will not to run model again.\n","  \n","\n","  '''\n","  # Create lists to store train and valid loss at each epoch\n","\n","  train_loss_history = []\n","  valid_loss_history = []\n","  train_acc_history = []\n","  valid_acc_history = []\n","  delta = 0\n","  best_score = None\n","  valid_loss_min = np.Inf\n","  counter_early_stop=0\n","  early_stop=False\n","\n","\n","  # Iterate for the given number of epochs\n","  for epoch in range(epochs):\n","    t0 = datetime.now()\n","    # Get train loss and accuracy for one epoch\n","\n","    train_loss, train_acc = train(train_loader, model, optimizer, loss_function, \n","                                  wandb.config.log_batch, wandb.config.log_interval,\n","                                  wandb.config.grad_clipping, wandb.config.max_norm)\n","    valid_loss, valid_acc = valid(valid_loader, model, optimizer, loss_function,\n","                                    wandb.config.log_batch, wandb.config.log_interval)\n","\n","    dt = datetime.now() - t0\n","\n","    # Save history of the Losses and accuracy\n","    train_loss_history.append(train_loss)\n","    train_acc_history.append(train_acc)\n","    valid_loss_history.append(valid_loss)\n","    valid_acc_history.append(valid_acc)\n","\n","    if early_stopping:\n","      score = -valid_loss\n","      if best_score is None:\n","        best_score=score\n","        print(f'Validation loss has decreased ({valid_loss_min:.6f} --> {valid_loss:.6f}). Saving Model...')\n","        torch.save(model.state_dict(), file_model)\n","        valid_loss_min = valid_loss\n","\n","      elif score < best_score + delta:\n","        counter_early_stop += 1\n","        print(f'Early stoping counter: {counter_early_stop} out of {patience}')\n","        if counter_early_stop > patience:\n","          early_stop = True\n","\n","      \n","      else:\n","        best_score = score\n","        print(f'Validation loss has decreased ({valid_loss_min:.6f} --> {valid_loss:.6f}). Saving model...')\n","        torch.save(model.state_dict(), file_model)\n","        counter_early_stop=0\n","        valid_loss_min = valid_loss\n","\n","      if early_stop:\n","        print('Early Stopping')\n","        break\n","\n","    else:\n","\n","      score = -valid_loss\n","      if best_score is None:\n","        best_score=score\n","        print(f'Validation loss has decreased ({valid_loss_min:.6f} --> {valid_loss:.6f}). Saving Model...')\n","        torch.save(model.state_dict(), file_model)\n","        valid_loss_min = valid_loss\n","\n","      elif score < best_score + delta:\n","        print(f'Validation loss has not decreased ({valid_loss_min:.6f} --> {valid_loss:.6f}). Not Saving Model...')\n","      \n","      else:\n","        best_score = score\n","        print(f'Validation loss has decreased ({valid_loss_min:.6f} --> {valid_loss:.6f}). Saving model...')\n","        torch.save(model.state_dict(), file_model)\n","        valid_loss_min = valid_loss\n","\n","\n","\n","    # Log the train and valid loss to W&B\n","    wandb.log({f\"Train epoch Loss :\": train_loss, f\"Valid epoch Loss :\": valid_loss })\n","    wandb.log({f\"Train epoch Acc :\": train_acc, f\"Valid epoch Acc :\": valid_acc})\n","\n","\n","\n","    # Print the train loss and accuracy for given number of epochs, batch size and number of samples\n","    print(f'Epoch : {epoch+1} / {epochs}')\n","    print(f'Time to complete {epoch+1} is {dt}')\n","    # print(f'Learning rate: {scheduler.get_last_lr()}')\n","    print(f'Learning rate: {scheduler._last_lr[0]}')\n","    print(f'Train Loss: {train_loss : .4f} | Train Accuracy: {train_acc * 100 : .4f}%')\n","    print(f'Valid Loss: {valid_loss : .4f} | Valid Accuracy: {valid_acc * 100 : .4f}%')\n","    print()\n","    torch.cuda.empty_cache()\n","\n","  return train_loss_history, train_acc_history, valid_loss_history, valid_acc_history\n"],"execution_count":69,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Yte1HzNniWlr"},"source":["#Model Training"]},{"cell_type":"markdown","metadata":{"id":"8fLa11d5rPZv"},"source":["## **Meta data**\n","\n"]},{"cell_type":"code","metadata":{"id":"F3ISekWSV84a","executionInfo":{"status":"ok","timestamp":1636949199766,"user_tz":360,"elapsed":34,"user":{"displayName":"Shishir sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgQXaVDw08iapj6wCi7UM1wKF5TLN-xVAZbzWZzDA=s64","userId":"18124275142639548991"}}},"source":["hyperparameters = dict(\n","    epochs = 20,\n","    output_dim = 10, \n","    \n","    batch_size = 256,\n","    learning_rate = 0.01,\n","    dataset=\"CIFAR10\",\n","    architecture=\"CNN\",\n","    log_interval = 25,\n","    log_batch = True,\n","    file_model = lecture_folder/'CIFAR10_CNN.pt',\n","    grad_clipping = True,\n","    max_norm = 1,\n","    patience = 5,\n","    early_stopping = True,\n","    weight_decay = 0,\n","    scheduler_factor = 0,\n","    scheduler_patience = 0,\n","   )\n","\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"],"execution_count":70,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xH25I8Pikqpb"},"source":["## Initialize wandb"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":692,"referenced_widgets":["4a0eaa78db2a45cc8d4c5b66789c4b0a","5befefdd7bc342f9ab18f2efb671b5b6","0418001a927d4f7ba6c51105f483d2fd","450e20d81af94d1598f9c6a4cbd5f777","f79f30d333ab45c6b5785eb61e87a2de","dba768a73a1c45e5b796b34e7a69da73","fe42536b0d534b59bf0268fafe45d301","b9f6c8197e444d3e9b655dfc3c9c0eaf"]},"id":"9Zp9fDrAheXc","executionInfo":{"status":"ok","timestamp":1636949206265,"user_tz":360,"elapsed":6533,"user":{"displayName":"Shishir sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgQXaVDw08iapj6wCi7UM1wKF5TLN-xVAZbzWZzDA=s64","userId":"18124275142639548991"}},"outputId":"32abe2b1-6dea-4a64-eee0-4045a461597d"},"source":["wandb.init(name = 'CIFAR10CNN_hw5', project = 'CIFAR10_CNN', config = hyperparameters)"],"execution_count":71,"outputs":[{"output_type":"display_data","data":{"text/html":["Finishing last run (ID:36wvg35e) before initializing another..."],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":["<br/>Waiting for W&B process to finish, PID 439... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4a0eaa78db2a45cc8d4c5b66789c4b0a","version_minor":0,"version_major":2},"text/plain":["VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\">\n","<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train Batch Acc :</td><td>▁▂▃▅▄▄▅▆▅▆▅▇▅▆▆▆▇▇▇▇▆▇▇▇▇▇▇█▇▇▇▇█▇█████▇</td></tr><tr><td>Train Batch Loss  :</td><td>█▇▅▄▄▄▄▃▄▃▃▃▃▃▃▃▂▂▂▂▃▂▂▂▁▂▂▁▁▂▂▂▁▂▁▁▁▁▁▂</td></tr><tr><td>Train epoch Acc :</td><td>▁▄▅▆▆▇▇▇██</td></tr><tr><td>Train epoch Loss :</td><td>█▅▄▃▃▂▂▂▁▁</td></tr><tr><td>Valid Batch Accuracy :</td><td>▁▁▃▅▅▅▄▅▆▅▇███▇█</td></tr><tr><td>Valid Batch Loss  :</td><td>███▅▄▄▄▄▂▄▄▃▂▁▃▂</td></tr><tr><td>Valid epoch Acc :</td><td>▁▃▅▆▆▇▇▇██</td></tr><tr><td>Valid epoch Loss :</td><td>█▆▅▄▃▂▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n","<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train Batch Acc :</td><td>0.69141</td></tr><tr><td>Train Batch Loss  :</td><td>0.81189</td></tr><tr><td>Train epoch Acc :</td><td>0.75932</td></tr><tr><td>Train epoch Loss :</td><td>0.69246</td></tr><tr><td>Valid Batch Accuracy :</td><td>0.73047</td></tr><tr><td>Valid Batch Loss  :</td><td>0.77412</td></tr><tr><td>Valid epoch Acc :</td><td>0.7282</td></tr><tr><td>Valid epoch Loss :</td><td>0.77617</td></tr></table>\n","</div></div>\n","Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n","<br/>Synced <strong style=\"color:#cdcd00\">CIFAR10CNN_hw5</strong>: <a href=\"https://wandb.ai/sxs200126/CIFAR10_CNN/runs/36wvg35e\" target=\"_blank\">https://wandb.ai/sxs200126/CIFAR10_CNN/runs/36wvg35e</a><br/>\n","Find logs at: <code>./wandb/run-20211115_040252-36wvg35e/logs</code><br/>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":["Successfully finished last run (ID:36wvg35e). Initializing new run:<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":["\n","                    Syncing run <strong><a href=\"https://wandb.ai/sxs200126/CIFAR10_CNN/runs/3319x8bl\" target=\"_blank\">CIFAR10CNN_hw5</a></strong> to <a href=\"https://wandb.ai/sxs200126/CIFAR10_CNN\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n","\n","                "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["<wandb.sdk.wandb_run.Run at 0x7f759e4fd750>"],"text/html":["<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/sxs200126/CIFAR10_CNN/runs/3319x8bl?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"]},"metadata":{},"execution_count":71}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1GUCW6ipgS8p","executionInfo":{"status":"ok","timestamp":1636949206271,"user_tz":360,"elapsed":54,"user":{"displayName":"Shishir sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgQXaVDw08iapj6wCi7UM1wKF5TLN-xVAZbzWZzDA=s64","userId":"18124275142639548991"}},"outputId":"fbbeb6eb-d20d-43d1-932b-0eb1d02ca16d"},"source":["wandb.config.device = device\n","print(wandb.config.device )"],"execution_count":72,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda:0\n"]}]},{"cell_type":"markdown","metadata":{"id":"B9DjhWa3k-Gk"},"source":["## Specify Dataloader, Loss_function, Model, Optimizer, Weight Initialization"]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-10-30T03:59:34.389768Z","iopub.status.busy":"2021-10-30T03:59:34.389603Z","iopub.status.idle":"2021-10-30T03:59:34.435800Z","shell.execute_reply":"2021-10-30T03:59:34.435486Z","shell.execute_reply.started":"2021-10-30T03:59:34.389752Z"},"tags":[],"id":"z7zBv-QN-quA","executionInfo":{"status":"ok","timestamp":1636949206274,"user_tz":360,"elapsed":35,"user":{"displayName":"Shishir sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgQXaVDw08iapj6wCi7UM1wKF5TLN-xVAZbzWZzDA=s64","userId":"18124275142639548991"}}},"source":["# Fix seed value\n","SEED = 2345\n","random.seed(SEED)\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","torch.cuda.manual_seed(SEED)\n","torch.backends.cudnn.deterministic = True\n","\n","# Data Loader\n","train_loader = torch.utils.data.DataLoader(trainset, batch_size=wandb.config.batch_size, shuffle = True)\n","valid_loader = torch.utils.data.DataLoader(validset, batch_size=wandb.config.batch_size, shuffle = False)\n","test_loader = torch.utils.data.DataLoader(testset, batch_size=wandb.config.batch_size,   shuffle = False)\n","\n","# cross entropy loss function\n","loss_function = nn.CrossEntropyLoss()\n","\n","# device \n","model = CIFAR10CNN()\n","\n","def init_weights(m):\n","  if type(m) == nn.Conv2d:\n","        torch.nn.init.kaiming_normal_(m.weight)\n","        torch.nn.init.zeros_(m.bias)\n","\n","  if type(m) == nn.Conv2d:\n","        torch.nn.init.kaiming_normal_(m.weight)\n","        torch.nn.init.zeros_(m.bias)\n","\n","        \n","# apply initialization recursively  to all modules\n","# model.apply(init_weights)\n","\n","wandb.config.init_weights = init_weights\n","\n","# put model to GPUs\n","model.to(wandb.config.device)\n","\n","# Intialize stochiastic gradient descent optimizer\n","optimizer = torch.optim.SGD(model.parameters(), lr = wandb.config.learning_rate, weight_decay=wandb.config.weight_decay, momentum = 0.9)\n","#optimizer = torch.optim.Adam(model.parameters(), lr = wandb.config.learning_rate, weight_decay=wandb.config.weight_decay)\n","\n","wandb.config.optimizer = optimizer\n","\n","#scheduler = ReduceLROnPlateau(optimizer, mode='min', factor= wandb.config.scheduler_factor, \n","#                              patience=wandb.config.scheduler_patience, verbose=True)\n","\n","scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.1, total_steps=len(train_loader) * 10 , epochs=10, three_phase=True)\n","\n","#scheduler = StepLR(optimizer, gamma=0.4,step_size=1, verbose=True)"],"execution_count":73,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CPDnF9JbSHdX"},"source":["## Sanity Check\n","- Check the loss without any training. For Cross entropy the expected value will be log(number of classes)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GWkFxtEqSKlW","executionInfo":{"status":"ok","timestamp":1636949206483,"user_tz":360,"elapsed":239,"user":{"displayName":"Shishir sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgQXaVDw08iapj6wCi7UM1wKF5TLN-xVAZbzWZzDA=s64","userId":"18124275142639548991"}},"outputId":"5af55ec2-19ea-4252-d1ea-98e421fcc023"},"source":["# Fix seed value\n","\n","SEED = 2345\n","random.seed(SEED)\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","torch.cuda.manual_seed(SEED)\n","torch.backends.cudnn.deterministic = True\n","\n","for input, targets in train_loader:\n","  \n","  # move inputs and outputs to GPUs\n","  input = input.to(device)\n","  targets = targets.to(device)\n","  model.eval()\n","  # Forward pass\n","  output = model(input)\n","  loss = loss_function(output, targets)\n","  print(f'Actual loss: {loss}')\n","  break\n","\n","print(f'Expected Theoretical loss: {np.log(10)}')\n","\n"],"execution_count":74,"outputs":[{"output_type":"stream","name":"stdout","text":["Actual loss: 2.3017776012420654\n","Expected Theoretical loss: 2.302585092994046\n"]}]},{"cell_type":"markdown","metadata":{"id":"htWT1-Nhlw3m"},"source":["## Train Model and Save best model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MwnGtxo3B2nD","executionInfo":{"status":"ok","timestamp":1636949206486,"user_tz":360,"elapsed":22,"user":{"displayName":"Shishir sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgQXaVDw08iapj6wCi7UM1wKF5TLN-xVAZbzWZzDA=s64","userId":"18124275142639548991"}},"outputId":"4f5f46f5-5420-4f1b-e447-06f2df61f595"},"source":["wandb.watch(model, log = 'all', log_freq=25, log_graph=True)"],"execution_count":75,"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n"]},{"output_type":"execute_result","data":{"text/plain":["[<wandb.wandb_torch.TorchGraph at 0x7f75a6ef8450>]"]},"metadata":{},"execution_count":75}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QyAaOEg5DdKp","executionInfo":{"status":"ok","timestamp":1636949458935,"user_tz":360,"elapsed":252458,"user":{"displayName":"Shishir sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgQXaVDw08iapj6wCi7UM1wKF5TLN-xVAZbzWZzDA=s64","userId":"18124275142639548991"}},"outputId":"bcfbb31d-1670-459e-acd7-8b33195e7612"},"source":["example_ct_train, batch_ct_train, example_ct_valid, batch_ct_valid = 0, 0, 0, 0\n","train_loss_history, train_acc_history, valid_loss_history, valid_acc_history = train_loop(train_loader, valid_loader, model, loss_function, optimizer, \n","                                                                                          wandb.config.epochs, wandb.config.device,\n","                                                                                          wandb.config.patience, wandb.config.early_stopping,\n","                                                                                          wandb.config.file_model)"],"execution_count":76,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:154: UserWarning:\n","\n","The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","\n"]},{"output_type":"stream","name":"stdout","text":["Validation loss has decreased (inf --> 1.378038). Saving Model...\n","Epoch : 1 / 20\n","Time to complete 1 is 0:00:12.859841\n","Learning rate: 0.0040020362658931\n","Train Loss:  1.7250 | Train Accuracy:  37.1650%\n","Valid Loss:  1.3780 | Valid Accuracy:  49.1700%\n","\n","Validation loss has decreased (1.378038 --> 1.185834). Saving model...\n","Epoch : 2 / 20\n","Time to complete 2 is 0:00:12.722852\n","Learning rate: 0.004001507859870884\n","Train Loss:  1.3082 | Train Accuracy:  52.6825%\n","Valid Loss:  1.1858 | Valid Accuracy:  57.6000%\n","\n","Validation loss has decreased (1.185834 --> 1.101430). Saving model...\n","Epoch : 3 / 20\n","Time to complete 3 is 0:00:12.894171\n","Learning rate: 0.004001300850483738\n","Train Loss:  1.1585 | Train Accuracy:  58.8225%\n","Valid Loss:  1.1014 | Valid Accuracy:  61.0300%\n","\n","Validation loss has decreased (1.101430 --> 0.997512). Saving model...\n","Epoch : 4 / 20\n","Time to complete 4 is 0:00:12.801894\n","Learning rate: 0.004001066965313577\n","Train Loss:  1.0376 | Train Accuracy:  63.3475%\n","Valid Loss:  0.9975 | Valid Accuracy:  64.4500%\n","\n","Validation loss has decreased (0.997512 --> 0.923130). Saving model...\n","Epoch : 5 / 20\n","Time to complete 5 is 0:00:12.670565\n","Learning rate: 0.004000913774758794\n","Train Loss:  0.9475 | Train Accuracy:  66.5500%\n","Valid Loss:  0.9231 | Valid Accuracy:  67.2100%\n","\n","Validation loss has decreased (0.923130 --> 0.878513). Saving model...\n","Epoch : 6 / 20\n","Time to complete 6 is 0:00:12.695842\n","Learning rate: 0.004000827581318811\n","Train Loss:  0.8774 | Train Accuracy:  68.9800%\n","Valid Loss:  0.8785 | Valid Accuracy:  68.9600%\n","\n","Validation loss has decreased (0.878513 --> 0.863896). Saving model...\n","Epoch : 7 / 20\n","Time to complete 7 is 0:00:12.653573\n","Learning rate: 0.004000800270528251\n","Train Loss:  0.8256 | Train Accuracy:  71.0650%\n","Valid Loss:  0.8639 | Valid Accuracy:  69.1100%\n","\n","Validation loss has decreased (0.863896 --> 0.837531). Saving model...\n","Epoch : 8 / 20\n","Time to complete 8 is 0:00:12.657653\n","Learning rate: 0.004000752170683908\n","Train Loss:  0.7795 | Train Accuracy:  72.4825%\n","Valid Loss:  0.8375 | Valid Accuracy:  70.7900%\n","\n","Validation loss has decreased (0.837531 --> 0.769821). Saving model...\n","Epoch : 9 / 20\n","Time to complete 9 is 0:00:12.489365\n","Learning rate: 0.004000635468687619\n","Train Loss:  0.7313 | Train Accuracy:  74.3350%\n","Valid Loss:  0.7698 | Valid Accuracy:  72.8600%\n","\n","Early stoping counter: 1 out of 5\n","Epoch : 10 / 20\n","Time to complete 10 is 0:00:12.551166\n","Learning rate: 0.004000645995268309\n","Train Loss:  0.6925 | Train Accuracy:  75.9325%\n","Valid Loss:  0.7762 | Valid Accuracy:  72.8200%\n","\n","Validation loss has decreased (0.769821 --> 0.739868). Saving model...\n","Epoch : 11 / 20\n","Time to complete 11 is 0:00:12.629175\n","Learning rate: 0.0040005869799916716\n","Train Loss:  0.6642 | Train Accuracy:  76.7025%\n","Valid Loss:  0.7399 | Valid Accuracy:  73.8200%\n","\n","Validation loss has decreased (0.739868 --> 0.719953). Saving model...\n","Epoch : 12 / 20\n","Time to complete 12 is 0:00:12.445722\n","Learning rate: 0.004000555805562397\n","Train Loss:  0.6346 | Train Accuracy:  77.7275%\n","Valid Loss:  0.7200 | Valid Accuracy:  74.1900%\n","\n","Validation loss has decreased (0.719953 --> 0.714853). Saving model...\n","Epoch : 13 / 20\n","Time to complete 13 is 0:00:12.442012\n","Learning rate: 0.004000547959317341\n","Train Loss:  0.6045 | Train Accuracy:  78.9325%\n","Valid Loss:  0.7149 | Valid Accuracy:  74.9200%\n","\n","Validation loss has decreased (0.714853 --> 0.713297). Saving model...\n","Epoch : 14 / 20\n","Time to complete 14 is 0:00:12.468405\n","Learning rate: 0.004000545575477271\n","Train Loss:  0.5722 | Train Accuracy:  79.9475%\n","Valid Loss:  0.7133 | Valid Accuracy:  75.5900%\n","\n","Validation loss has decreased (0.713297 --> 0.690537). Saving model...\n","Epoch : 15 / 20\n","Time to complete 15 is 0:00:12.388739\n","Learning rate: 0.00400051131552441\n","Train Loss:  0.5462 | Train Accuracy:  81.1350%\n","Valid Loss:  0.6905 | Valid Accuracy:  75.6800%\n","\n","Early stoping counter: 1 out of 5\n","Epoch : 16 / 20\n","Time to complete 16 is 0:00:12.573552\n","Learning rate: 0.004000526334841659\n","Train Loss:  0.5180 | Train Accuracy:  81.7675%\n","Valid Loss:  0.7006 | Valid Accuracy:  75.4700%\n","\n","Validation loss has decreased (0.690537 --> 0.679621). Saving model...\n","Epoch : 17 / 20\n","Time to complete 17 is 0:00:12.450999\n","Learning rate: 0.004000495277484084\n","Train Loss:  0.4948 | Train Accuracy:  82.8275%\n","Valid Loss:  0.6796 | Valid Accuracy:  76.3400%\n","\n","Early stoping counter: 1 out of 5\n","Epoch : 18 / 20\n","Time to complete 18 is 0:00:12.406154\n","Learning rate: 0.00400050784786779\n","Train Loss:  0.4686 | Train Accuracy:  83.7700%\n","Valid Loss:  0.6882 | Valid Accuracy:  76.0600%\n","\n","Validation loss has decreased (0.679621 --> 0.668451). Saving model...\n","Epoch : 19 / 20\n","Time to complete 19 is 0:00:12.470674\n","Learning rate: 0.004000479130347276\n","Train Loss:  0.4529 | Train Accuracy:  84.3950%\n","Valid Loss:  0.6685 | Valid Accuracy:  76.7000%\n","\n","Validation loss has decreased (0.668451 --> 0.667706). Saving model...\n","Epoch : 20 / 20\n","Time to complete 20 is 0:00:12.456013\n","Learning rate: 0.00400047806269356\n","Train Loss:  0.4253 | Train Accuracy:  85.3325%\n","Valid Loss:  0.6677 | Valid Accuracy:  77.2200%\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"qNODEpa2h0yc"},"source":["## Add Visulaization"]},{"cell_type":"markdown","metadata":{"id":"KWkYcdLm6_Am"},"source":["### Add training images"]},{"cell_type":"code","metadata":{"id":"fkUIr9I3Ogl3","executionInfo":{"status":"ok","timestamp":1636949458939,"user_tz":360,"elapsed":35,"user":{"displayName":"Shishir sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgQXaVDw08iapj6wCi7UM1wKF5TLN-xVAZbzWZzDA=s64","userId":"18124275142639548991"}}},"source":["# Get some random training images\n","dataiter = iter(train_loader)\n","images, labels = dataiter.next()\n","\n","# Create grid of images\n","img_grid = torchvision.utils.make_grid(images[0:50], nrow = 5)\n","\n","# Logging to W&B\n","images = wandb.Image(img_grid, caption = \"Sample images\")\n","wandb.log({\"examples\": images})"],"execution_count":77,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oXO9Cqxb7JN_"},"source":["### Add Loss plot"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q-Vgzk5ppgbR","executionInfo":{"status":"ok","timestamp":1636949460031,"user_tz":360,"elapsed":1118,"user":{"displayName":"Shishir sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgQXaVDw08iapj6wCi7UM1wKF5TLN-xVAZbzWZzDA=s64","userId":"18124275142639548991"}},"outputId":"8e4b8e2a-d75a-4b82-e940-f388ab2ab95a"},"source":["# Plot the train loss and test loss per iteration\n","fig = plt.figure(0)\n","plt.plot(train_loss_history, label = 'train loss')\n","plt.plot(valid_loss_history, label = 'valid loss')\n","plt.legend()\n","\n","# Log the plot to W&B\n","wandb.log({\"train-test loss per epoch\": fig})"],"execution_count":78,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n","\n","Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n","\n","/usr/local/lib/python3.7/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n","\n","I found a path object that I don't think is part of a bar chart. Ignoring.\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"FWCLH47azD6j"},"source":["# **Accuracy and Predictions**\n","\n","Now we have final values for weights and bias after training the model. We will use these values to make predictions on the test dataset."]},{"cell_type":"markdown","metadata":{"id":"uzDX4D6EvcVC"},"source":["## Function to get predictions"]},{"cell_type":"code","metadata":{"id":"M6KZqsnqQFVu","executionInfo":{"status":"ok","timestamp":1636949460034,"user_tz":360,"elapsed":91,"user":{"displayName":"Shishir sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgQXaVDw08iapj6wCi7UM1wKF5TLN-xVAZbzWZzDA=s64","userId":"18124275142639548991"}}},"source":["def get_acc_pred(data_loader, model):\n","  \"\"\" \n","  Function to get predictions for a given test set and calculate accuracy.\n","  Input: Iterator to the test set.\n","  Output: Prections and Accuracy for test set.\n","  \"\"\"\n","  with torch.no_grad():\n","    # Array to store predicted labels\n","    predictions = torch.Tensor()\n","    predictions = predictions.to(device)\n","\n","    # Array to store actual labels\n","    y = torch.Tensor()\n","    y = y.to(device)\n","    # Iterate over batches from test set\n","    for input, targets in data_loader:\n","      \n","      # move inputs and outputs to GPUs\n","      input = input.to(device)\n","      targets = targets.to(device)\n","\n","      # Calculated the predicted labels\n","      output = model(input)\n","\n","      # Choose the label with maximum probability\n","      indices = torch.argmax(output, dim = 1)\n","\n","      # Add the predicted labels to the array\n","      predictions = torch.cat((predictions, indices)) \n","\n","      # Add the actual labels to the array\n","      y = torch.cat((y, targets)) \n","\n","    # Check for complete dataset if actual and predicted labels are same or not\n","    # Calculate accuracy\n","    acc = (predictions == y).float().mean()\n","\n","  # Return array containing predictions and accuracy\n","  return predictions, acc\n","  "],"execution_count":79,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lK-g-bSTvkl8"},"source":["## Load saved model from file "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QVT_qlEivpER","executionInfo":{"status":"ok","timestamp":1636949460036,"user_tz":360,"elapsed":86,"user":{"displayName":"Shishir sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgQXaVDw08iapj6wCi7UM1wKF5TLN-xVAZbzWZzDA=s64","userId":"18124275142639548991"}},"outputId":"03b65a73-8b13-4f52-e124-ece607a8b722"},"source":["model_CNN =  CIFAR10CNN()\n","model_CNN.to(device)\n","model_CNN.load_state_dict(torch.load(wandb.config.file_model))"],"execution_count":80,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":80}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rKNCkt_XeCZ1","executionInfo":{"status":"ok","timestamp":1636949460038,"user_tz":360,"elapsed":59,"user":{"displayName":"Shishir sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgQXaVDw08iapj6wCi7UM1wKF5TLN-xVAZbzWZzDA=s64","userId":"18124275142639548991"}},"outputId":"2c2cdfd4-9a35-4127-dc8e-023b6ded9bc9"},"source":["print(wandb.config.file_model)"],"execution_count":81,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Deep Learning/HW5/CIFAR10_CNN.pt\n"]}]},{"cell_type":"code","metadata":{"id":"6mZ5tlp53hi7","executionInfo":{"status":"ok","timestamp":1636949461740,"user_tz":360,"elapsed":1745,"user":{"displayName":"Shishir sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgQXaVDw08iapj6wCi7UM1wKF5TLN-xVAZbzWZzDA=s64","userId":"18124275142639548991"}}},"source":["# Get the prediction and accuracy for the test dataset\n","predictions, acc_test = get_acc_pred(test_loader, model_CNN)"],"execution_count":82,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3v2z0oFcRjrF","executionInfo":{"status":"ok","timestamp":1636949461746,"user_tz":360,"elapsed":59,"user":{"displayName":"Shishir sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgQXaVDw08iapj6wCi7UM1wKF5TLN-xVAZbzWZzDA=s64","userId":"18124275142639548991"}},"outputId":"dd0fece9-2956-4ddb-8bf5-3cc4556314a7"},"source":["# Print Accuracy for test dataset\n","print(acc_test * 100)\n","wandb.config.test_accuracy = acc_test"],"execution_count":83,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(75.1900, device='cuda:0')\n"]}]}]}