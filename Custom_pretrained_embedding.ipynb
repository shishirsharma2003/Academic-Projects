{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Shishir_nlp_hw4_task4.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Vl3eIEYFkgP7"},"source":["# **Use custom pretrained embeddings with sklearn**\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"gTd5DfBAqbc6"},"source":["# Import libraries"]},{"cell_type":"code","metadata":{"id":"YN34PmjL51ID","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638646724223,"user_tz":360,"elapsed":11910,"user":{"displayName":"Shishir sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgQXaVDw08iapj6wCi7UM1wKF5TLN-xVAZbzWZzDA=s64","userId":"18124275142639548991"}},"outputId":"08641576-912e-477c-ef54-0fc69595150b"},"source":["!pip install -U spacy\n","!pip install -U gensim\n","!pip install scikit-multilearn\n","#pip install neattext"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (3.2.0)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.6)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.19.5)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.3.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.4.0)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.4.2)\n","Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.0)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.8.2)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.6)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.6)\n","Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.62.3)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.8)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.11.3)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.1)\n","Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.6.1)\n","Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.10.0.2)\n","Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /usr/local/lib/python3.7/dist-packages (from spacy) (8.0.13)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.6)\n","Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.8.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (21.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy) (3.6.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy) (3.0.6)\n","Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy) (5.2.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy) (7.1.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy) (2.0.1)\n","Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (4.1.2)\n","Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n","Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.2.1)\n","Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.19.5)\n","Requirement already satisfied: scikit-multilearn in /usr/local/lib/python3.7/dist-packages (0.2.0)\n"]}]},{"cell_type":"code","metadata":{"id":"TqYqOtp5yluv"},"source":["# Importing the necessary libraries\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import plotly.io as pio\n","pio.renderers.default = 'colab'\n","import joblib\n","import numpy as np\n","import pandas as pd\n","import re\n","from bs4 import BeautifulSoup\n","import random\n","from datetime import datetime\n","from pathlib import Path\n","from scipy.sparse import hstack\n","from collections import Counter, OrderedDict\n","\n","from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer, TfidfVectorizer\n","from sklearn.base import BaseEstimator, TransformerMixin\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import confusion_matrix\n","from sklearn.model_selection import train_test_split\n","from sklearn.pipeline import Pipeline\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.naive_bayes import GaussianNB,MultinomialNB\n","from sklearn.metrics import accuracy_score,hamming_loss,classification_report\n","from skmultilearn.problem_transform import BinaryRelevance\n","from skmultilearn.problem_transform import ClassifierChain\n","from skmultilearn.problem_transform import LabelPowerset\n","from skmultilearn.adapt import MLkNN\n","import skmultilearn\n","# learning Curves\n","from sklearn.model_selection import learning_curve\n","\n","# draws a confusion matrix\n","from sklearn.metrics import plot_confusion_matrix \n","\n","from gensim.models import Word2Vec\n","from gensim.models import KeyedVectors\n","import gensim\n","\n","import spacy\n","from spacy.matcher import Matcher\n","from spacy.tokens import Token"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XJPqqFJulaGW","executionInfo":{"status":"ok","timestamp":1638646739580,"user_tz":360,"elapsed":5,"user":{"displayName":"Shishir sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgQXaVDw08iapj6wCi7UM1wKF5TLN-xVAZbzWZzDA=s64","userId":"18124275142639548991"}},"outputId":"fcb7040f-1e81-44de-a410-0f18fb0f7595"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","metadata":{"id":"omgjHGvS2VBQ"},"source":["data_folder = Path('/content/drive/MyDrive/NLP/Homework21')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ThYcWeURFC-k"},"source":["# specify the folder in googe drive where we will save dataset\n","basepath = '/content/drive/MyDrive/Data'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"27OJT5oq2WXI"},"source":["lecture_folder = Path('/content/drive/NLP')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AfxXCoF44R5q"},"source":["save_model_folder = lecture_folder /'saved_model'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Eh9unUh0HqWF"},"source":["spacy_folder = Path('/content/drive/MyDrive/Data/spacy/')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NfEbGDX2GgtF"},"source":["#url = 'https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.2.0/en_core_web_lg-3.2.0.tar.gz'\n","#!wget {url} -P {spacy_folder} "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Cc6hqTgXFlNA"},"source":["#import tarfile\n","#file = spacy_folder / 'en_core_web_lg-3.2.0.tar.gz'\n","#with  tarfile.open(file, 'r') as tar:\n","#  tar.extractall(path = spacy_folder)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4aHgXiPrJrQQ"},"source":["model = spacy_folder /'en_core_web_lg-3.2.0'/'en_core_web_lg'/'en_core_web_lg-3.2.0'\n","nlp = spacy.load(model, disable=['ner, parser'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nee9m9rBVlC9","executionInfo":{"status":"ok","timestamp":1638646744865,"user_tz":360,"elapsed":27,"user":{"displayName":"Shishir sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgQXaVDw08iapj6wCi7UM1wKF5TLN-xVAZbzWZzDA=s64","userId":"18124275142639548991"}},"outputId":"141246ee-13c1-4de8-e6c6-88a30b76072f"},"source":["#Checking spacy and gensim version.\n","# We will use latest versions.\n","print(f'spacy: {spacy.__version__}, gensim {gensim.__version__}')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["spacy: 3.2.0, gensim 4.1.2\n"]}]},{"cell_type":"markdown","metadata":{"id":"E8kZrjaFMoKH"},"source":["# Functions/Classes"]},{"cell_type":"markdown","metadata":{"id":"oIYaMzbBM8JJ"},"source":["## Learning Curves"]},{"cell_type":"markdown","metadata":{"id":"zD8Ih7LNPdqt"},"source":["Function for learning curves: The function below has been taken from sklearn official documentation: https://scikit-learn.org/stable/auto_examples/model_selection/plot_learning_curve.html#sphx-glr-auto-examples-model-selection-plot-learning-curve-py"]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-10-25T10:05:10.253834Z","iopub.status.busy":"2021-10-25T10:05:10.253702Z","iopub.status.idle":"2021-10-25T10:05:10.260531Z","shell.execute_reply":"2021-10-25T10:05:10.260231Z","shell.execute_reply.started":"2021-10-25T10:05:10.253820Z"},"id":"JgOesmtW-ac3","tags":[]},"source":["def plot_learning_curve(estimator, title, X, y, axes=None, ylim=None, cv=None,\n","                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n","    \"\"\"\n","    Generate 2 plots: the test and training learning curve, the training\n","    samples vs fit times curve.\n","\n","    Parameters\n","    ----------\n","    estimator : estimator instance\n","        An estimator instance implementing `fit` and `predict` methods which\n","        will be cloned for each validation.\n","\n","    title : str\n","        Title for the chart.\n","\n","    X : array-like of shape (n_samples, n_features)\n","        Training vector, where ``n_samples`` is the number of samples and\n","        ``n_features`` is the number of features.\n","\n","    y : array-like of shape (n_samples) or (n_samples, n_features)\n","        Target relative to ``X`` for classification or regression;\n","        None for unsupervised learning.\n","\n","    axes : array-like of shape (3,), default=None\n","        Axes to use for plotting the curves.\n","\n","    ylim : tuple of shape (2,), default=None\n","        Defines minimum and maximum y-values plotted, e.g. (ymin, ymax).\n","\n","    cv : int, cross-validation generator or an iterable, default=None\n","        Determines the cross-validation splitting strategy.\n","        Possible inputs for cv are:\n","\n","          - None, to use the default 5-fold cross-validation,\n","          - integer, to specify the number of folds.\n","          - :term:`CV splitter`,\n","          - An iterable yielding (train, test) splits as arrays of indices.\n","\n","        For integer/None inputs, if ``y`` is binary or multiclass,\n","        :class:`StratifiedKFold` used. If the estimator is not a classifier\n","        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n","\n","        Refer :ref:`User Guide <cross_validation>` for the various\n","        cross-validators that can be used here.\n","\n","    n_jobs : int or None, default=None\n","        Number of jobs to run in parallel.\n","        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n","        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n","        for more details.\n","\n","    train_sizes : array-like of shape (n_ticks,)\n","        Relative or absolute numbers of training examples that will be used to\n","        generate the learning curve. If the ``dtype`` is float, it is regarded\n","        as a fraction of the maximum size of the training set (that is\n","        determined by the selected validation method), i.e. it has to be within\n","        (0, 1]. Otherwise it is interpreted as absolute sizes of the training\n","        sets. Note that for classification the number of samples usually have\n","        to be big enough to contain at least one sample from each class.\n","        (default: np.linspace(0.1, 1.0, 5))\n","    \"\"\"\n","    if axes is None:\n","        _, axes = plt.subplots(1, 2, figsize=(10, 5))\n","\n","    axes[0].set_title(title)\n","    if ylim is not None:\n","        axes[0].set_ylim(*ylim)\n","    axes[0].set_xlabel(\"Training examples\")\n","    axes[0].set_ylabel(\"Score\")\n","\n","    train_sizes, train_scores, test_scores, fit_times, _ = \\\n","        learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs,\n","                       train_sizes=train_sizes,\n","                       return_times=True,\n","                       random_state=123)\n","    train_scores_mean = np.mean(train_scores, axis=1)\n","    train_scores_std = np.std(train_scores, axis=1)\n","    test_scores_mean = np.mean(test_scores, axis=1)\n","    test_scores_std = np.std(test_scores, axis=1)\n","    fit_times_mean = np.mean(fit_times, axis=1)\n","    fit_times_std = np.std(fit_times, axis=1)\n","\n","    # Plot learning curve\n","    axes[0].grid()\n","    axes[0].fill_between(train_sizes, train_scores_mean - train_scores_std,\n","                         train_scores_mean + train_scores_std, alpha=0.1,\n","                         color=\"r\")\n","    axes[0].fill_between(train_sizes, test_scores_mean - test_scores_std,\n","                         test_scores_mean + test_scores_std, alpha=0.1,\n","                         color=\"g\")\n","    axes[0].plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n","                 label=\"Training score\")\n","    axes[0].plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n","                 label=\"Cross-validation score\")\n","    axes[0].legend(loc=\"best\")\n","\n","    # Plot n_samples vs fit_times\n","    axes[1].grid()\n","    axes[1].plot(train_sizes, fit_times_mean, 'o-')\n","    axes[1].fill_between(train_sizes, fit_times_mean - fit_times_std,\n","                         fit_times_mean + fit_times_std, alpha=0.1)\n","    axes[1].set_xlabel(\"Training examples\")\n","    axes[1].set_ylabel(\"fit_times\")\n","    axes[1].set_title(\"Scalability of the model\")\n","\n","    return plt"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xAgi4QUGM4eZ"},"source":["## PreProcessor"]},{"cell_type":"code","metadata":{"id":"8AZZ9zG4FQ3Q"},"source":["class SpacyPreprocessor(BaseEstimator, TransformerMixin):\n","    np.random.seed(0)\n","    def __init__(self, lammetize=True, lower=True, remove_stop=True, remove_punct=True, remove_num=False):\n","        self.remove_stop = remove_stop\n","        self.remove_punct = remove_punct\n","        self.remove_num = remove_num\n","        self. lammetize = lammetize\n","        self.lower = lower\n","\n","    # helpfer functions for basic cleaning \n","    def basic_clean(self,text):\n","        return [re.sub(r'[\\n\\r]',' ',sentence) for sentence in text]\n","\n","    # helper function for pre-processing with spacy\n","    def spacy_preprocessor(self,texts): \n","        nlp=spacy.load(model, disable=['parser','ner'])\n","        ## Add @ as a prefix so that we can separate the word from its token\n","        ## Since we are using pretrained vectors - @ mentions will be different in the pre-trained vocab\n","        \n","        prefixes = list(nlp.Defaults.prefixes)\n","        prefixes += ['@']\n","        prefix_regex = spacy.util.compile_prefix_regex(prefixes)\n","        nlp.tokenizer.prefix_search = prefix_regex.search\n","     \n","        matcher = Matcher(nlp.vocab)\n","        if self.remove_stop:\n","            matcher.add(\"stop_words\", [[{\"is_stop\" : True}]])\n","        if self.remove_punct:\n","            matcher.add(\"punctuation\",[ [{\"is_punct\": True}]])\n","        if self.remove_num:\n","            matcher.add(\"numbers\", [[{\"like_num\": True}]])\n","        Token.set_extension('is_remove', default=False,force=True)\n","        cleaned_text=[]\n","\n","        for doc in nlp.pipe(texts,batch_size=64,disable=['parser','ner']):\n","            matches = matcher(doc)\n","            for _, start, end in matches:\n","                for token in doc[start:end]:\n","                    token._.is_remove =True\n","                    \n","            if self.lammetize:\n","                text = ' '.join(token.lemma_ for token in doc if (token._.is_remove==False))\n","            else:\n","                text = ' '.join(token.text for token in doc if (token._.is_remove==False))\n","            if self.lower:\n","                text=text.lower()\n","            cleaned_text.append(text)\n","        return cleaned_text\n","\n","    def fit(self, X,y=None):\n","        return self\n","\n","    def transform(self, X,y=None):\n","        x_clean = self.basic_clean(X)\n","        x_clean_final = self.spacy_preprocessor(x_clean)\n","        return x_clean_final"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dSSacOVpNGa5"},"source":["## Gensim vectorizer"]},{"cell_type":"code","metadata":{"id":"tqRz19LxNRPi"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kIK1Ug2BY0YP"},"source":["class GensimVectorizer(BaseEstimator,TransformerMixin):\n","  np.random.seed(0)\n","  def __init__(self,pretrained_vectors,unk_norm_init=False):\n","    # load in pre-trained word vectors\n","    self.pretrained_vectors= pretrained_vectors\n","    self.vec_size= self.pretrained_vectors.vector_size\n","    self.unk_norm_init = unk_norm_init\n","    self.pretrained_vectors_subset = {}\n","    self.words_not_in_pretrained = []\n","    self.count_missing = 0\n","    self.percent_missing = 0\n","\n","\n","  def fit(self, X,y=None):\n","    '''\n","    Gets the subset of pretrained vectors which are present in vocab\n","    X :  training sentences\n","    '''\n","    counter = Counter()\n","\n","    for sent in X:\n","        counter.update(sent.split())\n","    for token in counter:\n","        try:\n","            self.pretrained_vectors_subset[token] = self.pretrained_vectors.get_vector(token, norm=True)\n","        except:\n","            self.words_not_in_pretrained.append(token)\n","    \n","    ### save so that you can access this after you fit the vectorizer\n","    self.count_missing = len(self.words_not_in_pretrained )\n","    self.percent_missing = self.count_missing / len(counter)\n","    return self\n","    \n","  def transform(self,X,y=None):\n","    X_vector = np.zeros((len(X), self.vec_size))\n","    \n","    for i, sent in enumerate(X):\n","        sent_vector= np.zeros(self.vec_size)\n","        n=0\n","        tokens = sent.split()\n","        for word in tokens:\n","            if word in self.pretrained_vectors_subset.keys():\n","                word_vector=self.pretrained_vectors_subset[word]\n","                sent_vector+= word_vector\n","                n+= 1\n","            else:\n","                if self.unk_norm_init :\n","                    word_vector = np.random.normal(size=  self.vec_size)\n","                    sent_vector+= word_vector\n","                    n+= 1\n","        if n>0:\n","            X_vector[i] = sent_vector/n\n","    return X_vector"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"17xctemopjdA"},"source":["# **Multilabel_classification dataset Stackflow exchange**"]},{"cell_type":"markdown","metadata":{"id":"bTrbf15aROgj"},"source":["## Train/Test/Valid Dataset Importing cleaned data"]},{"cell_type":"code","metadata":{"id":"L2UmlkjkwVtI"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"or0BG4cyFooq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638646744866,"user_tz":360,"elapsed":21,"user":{"displayName":"Shishir sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgQXaVDw08iapj6wCi7UM1wKF5TLN-xVAZbzWZzDA=s64","userId":"18124275142639548991"}},"outputId":"85c40ca5-7261-4336-e49c-601e914a7aec"},"source":["# specify pathlib folder\n","# This is a system Path(PosixPath)\n","folder = Path(basepath)\n","folder"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["PosixPath('/content/drive/MyDrive/Data')"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"qyNWpAZbZj-k"},"source":["#file_csv = folder / 'multilabel_hw.csv'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i2ce7iBfaaIr"},"source":["df = pd.read_csv(folder / 'multilabel_hw.csv')\n","df.drop(columns= ['Unnamed: 0','Unnamed: 0.1','Id'], axis=1, inplace=True)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jHeuDGG203iE"},"source":["from sklearn.preprocessing import MultiLabelBinarizer\n","mlb = MultiLabelBinarizer()\n","df1 = pd.DataFrame(mlb.fit_transform(df['Tag_Number']),columns=mlb.classes_)\n","cols = [0,1,12,13]\n","df1.drop(df1.columns[cols],axis=1,inplace=True)\n","df_final = pd.concat([df,df1],axis=1)\n","df_final = df_final[:1000]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YNtQ9uSebASj"},"source":["X = df_final['Body'].values #drop(columns = ['Body','Tag','Tag_Number'])\n","\n","y = df_final[['0','1','2','3','4','5','6','7','8','9']].values\n","#y = y.reshape(1,-1)   #'0','1','2','3','4','5','6','7','8','9'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7swN3XQ52IUd"},"source":["# Create train/test/valid\n"]},{"cell_type":"code","metadata":{"id":"vUcdTMqkvO5P"},"source":["X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2,random_state=42)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yekjCL0Um56D"},"source":["preprocessor = SpacyPreprocessor()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H0Yxz12mnIJM"},"source":["X_train_cleaned= preprocessor.fit_transform(X_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0cKm8Nceoln0"},"source":["X_test_cleaned = preprocessor.transform(X_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O3cyM0NNK2KD"},"source":["X_train_cleaned = np.array(X_train_cleaned)\n","X_test_cleaned = np.array(X_test_cleaned)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"swFQDyWhpJNL"},"source":["file_X_train_cleaned_data = data_folder/ 'X_train_multiclass_clean_task4_1.pkl'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VMOnrfj3rM1g"},"source":["file_X_test_cleaned_data = data_folder/'X_test_multiclass_clean_task4_1.pkl'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gdf8pljOLL_B","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638646771535,"user_tz":360,"elapsed":245,"user":{"displayName":"Shishir sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgQXaVDw08iapj6wCi7UM1wKF5TLN-xVAZbzWZzDA=s64","userId":"18124275142639548991"}},"outputId":"b28c2d5e-d7bb-453c-de5b-765ca62bbc55"},"source":["joblib.dump(X_train_cleaned, file_X_train_cleaned_data) \n","joblib.dump(X_test_cleaned, file_X_test_cleaned_data) "],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['/content/drive/MyDrive/NLP/Homework21/X_test_multiclass_clean_task4_1.pkl']"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","metadata":{"id":"BwTRKOcb3CR4"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2f94n6S-6YCO"},"source":["# location of train and test files\n","file_X_train_cleaned_data = data_folder /'X_train_multiclass_clean_task4_1.pkl'\n","file_X_test_cleaned_data = data_folder /'X_test_multiclass_clean_task4_1.pkl'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JaGhAHWKLUE5"},"source":["X_train_cleaned = joblib.load(file_X_train_cleaned_data)\n","X_test_cleaned = joblib.load(file_X_test_cleaned_data)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Wi-VJiGeNZ_T"},"source":["# Classification Pipeline"]},{"cell_type":"code","metadata":{"id":"ABMWS5KWNxUU"},"source":["pretrained_vectors = KeyedVectors.load('/content/drive/MyDrive/NLP/Homework21/model_df.bin')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kpVaQsizZy8N"},"source":["#Creating sklearn pipeline and fitting train data\n","pipeline = Pipeline([\n","               ('vectorizer',GensimVectorizer(pretrained_vectors)),\n","               ('classifier',BinaryRelevance(LogisticRegression(max_iter = 1000)))\n","                ])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lqzv9nWm9b5Y"},"source":["#vectorizer = GensimVectorizer(pretrained_vectors)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ToCtNxUW9nQL"},"source":["#Xfeature = vectorizer.fit_transform(X_train_cleaned)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nLSZKW6I-e3e"},"source":["#type(Xfeature[0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nfKGd97W-FGr"},"source":["#model = ClassifierChain(MultinomialNB())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_9gAJWi4JkMR"},"source":["#from sklearn.preprocessing import MinMaxScaler\n","\n","#scaler = MinMaxScaler()\n","#Xfeature = scaler.fit_transform(Xfeature)\n","#X_test = scaler.fit_transform(X_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A3r_5XVd-N0q"},"source":["#model.fit(Xfeature,y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uCmu1IvxNeab"},"source":["## Hyperparamter Tuniung Round1"]},{"cell_type":"code","metadata":{"id":"7ez_2If8bWWd"},"source":["# now we create the grid with all the parameters that we would like to test\n","\n","param_grid_1 = {\n","    'classifier__classifier__C': [100000]\n","    #'classifier__classifier__max_iter':[100]\n","    }\n","\n","# now we set up the grid search with cross-validation\n","grid_logreg_1 = GridSearchCV(pipeline, param_grid_1,\n","                           cv=5, return_train_score= True, n_jobs=-1 )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"trdKotw589nc"},"source":["#X_train_cleaned"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Kcjg4WD089aH"},"source":["#pipeline.fit(X_train_cleaned,y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GIjE3g1scwm6","executionInfo":{"status":"ok","timestamp":1638646829290,"user_tz":360,"elapsed":49003,"user":{"displayName":"Shishir sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgQXaVDw08iapj6wCi7UM1wKF5TLN-xVAZbzWZzDA=s64","userId":"18124275142639548991"}},"outputId":"c2b0a059-f2ed-496c-b4b4-ce384eb1b311"},"source":["grid_logreg_1.fit(X_train_cleaned,y_train)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n","\n","lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n","\n","lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n","\n","lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["GridSearchCV(cv=5,\n","             estimator=Pipeline(steps=[('vectorizer',\n","                                        GensimVectorizer(pretrained_vectors=<gensim.models.fasttext.FastTextKeyedVectors object at 0x7fdf26d4d090>)),\n","                                       ('classifier',\n","                                        BinaryRelevance(classifier=LogisticRegression(max_iter=1000),\n","                                                        require_dense=[True,\n","                                                                       True]))]),\n","             n_jobs=-1, param_grid={'classifier__classifier__C': [100000]},\n","             return_train_score=True)"]},"metadata":{},"execution_count":42}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dwDWX2XodDtf","executionInfo":{"status":"ok","timestamp":1638646829291,"user_tz":360,"elapsed":60,"user":{"displayName":"Shishir sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgQXaVDw08iapj6wCi7UM1wKF5TLN-xVAZbzWZzDA=s64","userId":"18124275142639548991"}},"outputId":"bc2d6552-9dc0-4c1c-ad1d-16b00d50c784"},"source":["#Let's check the best_parameters from GridSearchCv for our model\n","print(grid_logreg_1.best_params_)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'classifier__classifier__C': 100000}\n"]}]},{"cell_type":"code","metadata":{"id":"jsA7dAlrO_7f"},"source":["plot_learning_curve(grid_logreg_1.best_estimator_, 'Learning Curves logreg', X_train, y_train, n_jobs=-1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XpdXzXK35aNW"},"source":["RAM is crashing here at learning curve function"]},{"cell_type":"code","metadata":{"id":"Z-udFO1aAkwn"},"source":["#let's check the train scores\n","print(grid_logreg_1.score(X_train_cleaned,y_train))\n","\n","#let's check the cross validation score\n","print(grid_logreg_1.best_score_)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DpBN859bRaQv"},"source":["#let's check the test scores\n","print(grid_logreg_1.score(X_test_cleaned,y_test))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tXXXgqG-ReJf"},"source":["plot_confusion_matrix(grid_logreg_1.best_estimator_, X_test_cleaned, y_test,\n","                                \n","                                 cmap=plt.cm.Blues,\n","                                 normalize = 'true')\n","plt.grid(False)\n","plt.show()"],"execution_count":null,"outputs":[]}]}